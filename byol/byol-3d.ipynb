{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BYOL in PyTorch\n",
    "\n",
    "This is written by Ying Liu (yili@di.ku.dk) who is the student in the Department of Computer Science at KÃ¸benhavns Universitet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center; align-items: center; background: white;\">\n",
    "    <img src=\"https://imgur.com/rBZRkOf.png\" style=\"width: 45%; margin-right: 1rem;\" />\n",
    "    <img src=\"https://imgur.com/uudkfAk.png\" style=\"width: 45%;\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "There are three important components, they are **encoder** $f$ (ResNet-50), **projector** $g$ and **predictor** $q$, respectively.\n",
    "\n",
    "- Online Network: encoder + projector + predictor, with parameters $\\theta$;\n",
    "\n",
    "- Target Network: encoder + projector, with parameters $\\xi$.\n",
    "\n",
    "During the training, the online network is updated by the **loss function** while the target network is updated slowly by the **exponential moving average** (EMA) of the online network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Area\n",
    "\n",
    "This contains import and global definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from functools import wraps\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Implementation\n",
    "\n",
    "Apply the original BYOL method to train the 3D Resnet model.\n",
    "\n",
    "**Citation**: [lucidrains](https://github.com/lucidrains/byol-pytorch/) and the other one [AI Summer](https://theaisummer.com/byol/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default: return the default value if the input value is None\n",
    "def default(val, def_val):\n",
    "    return def_val if val is None else val\n",
    "\n",
    "# flatten: flatten the tensor\n",
    "def flatten(t):\n",
    "    # original shape (N, C, D, H, W) -> (N, C*D*H*W)\n",
    "    return t.reshape(t.shape[0], -1)\n",
    "\n",
    "# signleton: cache the result of the function\n",
    "def singleton(cache_key):\n",
    "    def inner_fn(fn):\n",
    "        @wraps(fn)\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            instance = getattr(self, cache_key)\n",
    "            if instance is not None:\n",
    "                return instance\n",
    "\n",
    "            instance = fn(self, *args, **kwargs)\n",
    "            setattr(self, cache_key, instance)\n",
    "            return instance\n",
    "        return wrapper\n",
    "    return inner_fn\n",
    "\n",
    "# get_module_device: get the device of the module\n",
    "def get_module_device(module):\n",
    "    return next(module.parameters()).device\n",
    "\n",
    "# set_requires_grad: set the requires_grad attribute of the model\n",
    "def set_requires_grad(model, val):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "\n",
    "This loss function is defined by the original paper ==> BYOL. \n",
    "\n",
    "Normalize: torch.nn.functional (https://pytorch.org/docs/stable/generated/torch.nn.functional.normalize.html#torch.nn.functional.normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply L2 normalization to the last dimension. \n",
    "# The last dimension is the embedding dimension where stores the feature vector.\n",
    "def loss_fn(x, y):\n",
    "    x = F.normalize(x, dim=-1, p=2) \n",
    "    y = F.normalize(y, dim=-1, p=2)\n",
    "    return 2 - 2 * (x * y).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_apply: apply the function with the probability p\n",
    "class RandomApply(nn.Module):\n",
    "    # fn: the function for augmentation\n",
    "    def __init__(self, fn, p):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if random.random() > self.p:\n",
    "            return x\n",
    "        return self.fn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential moving average\n",
    "\n",
    "EMA: an exponential moving average (EMA), also known as an exponential weighted moving average (EWMA), is a first-order infinite impulse response filter that applies weighting factors which decrease exponentially, never reaching zero. This formulation is according to Hunter (1986). https://en.wikipedia.org/wiki/Moving_average\n",
    "\n",
    "By the paper, more precisely, given a target decay rate $\\tau \\in [0, 1]$, after each training step we perform the following update:\n",
    "\n",
    "$$\n",
    "\\xi \\leftarrow \\tau \\xi + (1 - \\tau) \\theta\n",
    "$$\n",
    "\n",
    "where $\\xi$ is the target network parameters and $\\theta$ is the online network parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA():\n",
    "    # given a target decay rate beta (which is tau in the paper)\n",
    "    def __init__(self, beta):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "    \n",
    "    # old corresponds to target (xi), new corresponds to online model (theta)\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new\n",
    "    \n",
    "def update_moving_average(ema_updater, ma_model, current_model):\n",
    "    '''\n",
    "    Update moving average of model weights.\n",
    "    ema_updater: EMA object\n",
    "    ma_model: the model with moving average weights (the target model)\n",
    "    current_model: the model with current weights (the online model)\n",
    "    '''\n",
    "    for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
    "        old_weight, up_weight = ma_params.data, current_params.data\n",
    "        ma_params.data = ema_updater.update_average(old_weight, up_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer perceptron\n",
    "\n",
    "A multilayer perceptron (MLP) is a name for a modern feedforward artificial neural network, consisting of fully connected neurons with a nonlinear kind of activation function, organized in at least three layers, notable for being able to distinguish data this is not linearly separable. It is a misnormer because the original perceptron used a Heaviside step function, instead of a nonlinear kind of activation function (used by modern networks). https://en.wikipedia.org/wiki/Multilayer_perceptron.\n",
    "\n",
    "By the paper, as in SimCLR, the representation $y$ is projected to a smaller space by a multi-layer perceptron (MLP) $g_{\\theta}$, and similarly for the target projection $g_{\\xi}$. This MLP consists in a linear layer with output size $4096$ followed by batch normalization, rectified linear units (ReLU), and a final layer with output dimension $256$. Contrary to SimCLR, the output of this MLP is not batch normalized. The predictor $q_{\\theta}$ uses the same architecutre as $g_{\\theta}$.\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html\n",
    "\n",
    "\n",
    "The difference between inplace=True and False is that it will modify the input directly, without allocating any additional output. https://discuss.pytorch.org/t/whats-the-difference-between-nn-relu-and-nn-relu-inplace-true/948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(dim, projection_size, hidden_size=4096):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim, hidden_size),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(hidden_size, projection_size)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetWrapper\n",
    "\n",
    "A wrapper class for the base neural network, will manage the interception of the hidden layer output and pipe it into the projector and predictor nets.\n",
    "\n",
    "Extract the representation $y$ and projection $z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWrapper(nn.Module):\n",
    "    # layer = -2 means the second last layer of the network\n",
    "    def __init__(self, net, projection_size, projection_hidden_size, layer=-2):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.layer = layer\n",
    "        \n",
    "        self.projector = None\n",
    "        self.projection_size = projection_size\n",
    "        self.projection_hidden_size = projection_hidden_size\n",
    "\n",
    "        self.hidden = {} # to store the hidden layer output when hook is registered\n",
    "        self.hook_registered = False\n",
    "\n",
    "    def _find_layer(self):\n",
    "        if type(self.layer) == str:\n",
    "            modules = dict([*self.net.named_modules()])\n",
    "            return modules.get(self.layer, None)\n",
    "        elif type(self.layer) == int:\n",
    "            children = [*self.net.children()]\n",
    "            return children[self.layer]\n",
    "        return None\n",
    "    \n",
    "    def _hook(self, _, input, output):\n",
    "        # store the output of the hidden layer\n",
    "        device = input[0].device\n",
    "        self.hidden[device] = flatten(output) # store the flattened output of the hidden layer\n",
    "\n",
    "    def _register_hook(self):\n",
    "        layer = self._find_layer()\n",
    "        assert layer is not None, f'hidden layer ({self.layer}) not found'\n",
    "        handle = layer.register_forward_hook(self._hook)\n",
    "        self.hook_registered = True\n",
    "\n",
    "    @singleton('projector')\n",
    "    # get the projection z\n",
    "    def _get_projector(self, hidden):\n",
    "        _, dim = hidden.shape\n",
    "        create_mlp_fn = MLP\n",
    "        projector = create_mlp_fn(dim, self.projection_size, self.projection_hidden_size)\n",
    "        return projector.to(hidden)\n",
    "    \n",
    "    # get the representation y\n",
    "    def get_representation(self, x):\n",
    "        if self.layer == -1:\n",
    "            return self.net(x)\n",
    "        \n",
    "        if not self.hook_registered:\n",
    "            self._register_hook()\n",
    "        \n",
    "        self.hidden.clear()\n",
    "        _ = self.net(x)\n",
    "        hidden = self.hidden[x.device] \n",
    "        self.hidden.clear()\n",
    "\n",
    "        assert hidden is not None, f'hidden layer {self.layer} never emitted an output'\n",
    "        return hidden\n",
    "    \n",
    "    def forward(self, x, return_projection = True):\n",
    "        representation = self.get_representation(x)\n",
    "        \n",
    "        if not return_projection:\n",
    "            return representation\n",
    "        \n",
    "        projector = self._get_projector(representation)\n",
    "        projection = projector(representation)\n",
    "        return projection, representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main BYOL\n",
    "\n",
    "By reading the paper https://github.com/Tencent/MedicalNet/blob/master/datasets/brains18.py, I was wondering if there is some step need to be changed in preprocessing the data. \n",
    "\n",
    "Maybe first constrain all the cts to be the shape of (320, 320, 320), then, drop invalid slices that are all zeros. Then, perform resized crop to (128, 128, 128) and normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYOL(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            net,\n",
    "            image_depth,\n",
    "            image_size,\n",
    "            hidden_layer=-2,\n",
    "            projection_size=256,\n",
    "            projection_hidden_size=4096,\n",
    "            augment_fn=None,\n",
    "            augment_fn2=None,\n",
    "            moving_average_decay=0.99\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "\n",
    "        # default SimCLR augmentation\n",
    "        DEFAULT_AUG == torch.nn.Sequential(\n",
    "            # haven't implemented\n",
    "        )\n",
    "\n",
    "        self.augment1 = default(augment_fn, DEFAULT_AUG)\n",
    "        self.augment2 = default(augment_fn2, self.augment1)\n",
    "\n",
    "        self.online_encoder = NetWrapper(\n",
    "                net,\n",
    "                projection_size,\n",
    "                projection_hidden_size,\n",
    "                layer = hidden_layer,\n",
    "        )\n",
    "\n",
    "        self.target_encoder = None\n",
    "        self.target_ema_updater = EMA(moving_average_decay)\n",
    "\n",
    "        self.online_predictor = MLP(projection_size, projection_size, projection_hidden_size)\n",
    "\n",
    "        # get the device of network and make warpper same device\n",
    "        device = get_module_device(net)\n",
    "        self.to(device)\n",
    "\n",
    "        # send a mock image tensor to instantiate singleton parameters\n",
    "        self.forward(torch.randn(2, 1, image_depth, image_size, image_size, device=device))\n",
    "\n",
    "    @singleton('target_encoder')\n",
    "    def _get_target_encoder(self):\n",
    "        target_encoder = copy.deepcopy(self.online_encoder)\n",
    "        set_requires_grad(target_encoder, False)\n",
    "        return target_encoder\n",
    "    \n",
    "    def reset_moving_average(self):\n",
    "        del self.target_encoder\n",
    "        self.target_encoder = None\n",
    "\n",
    "    def update_moving_average(self):\n",
    "        assert self.target_encoder is not None, 'target encoder has not been created yet'\n",
    "        update_moving_average(self.target_ema_updater, self.target_encoder, self.online_encoder)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            x,\n",
    "            return_embedding=False,\n",
    "            return_projection=True\n",
    "    ):\n",
    "        assert not (self.training and x.shape[0] == 1), 'you must have greater than 1 sample when training, due to the batchnorm in the projection layer'\n",
    "\n",
    "        if return_embedding:\n",
    "            return self.online_encoder(x, return_projection = return_projection)\n",
    "        \n",
    "        image_one, image_two = self.augment1(x), self.augment2(x)\n",
    "\n",
    "        images = torch.cat([image_one, image_two], dim=0)\n",
    "\n",
    "        online_projections, _ = self.online_encoder(images)\n",
    "        online_predications = self.online_predictor(online_projections)\n",
    "\n",
    "        online_pred_one, online_pred_two = online_predications.chunk(2, dim=0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            target_encoder = self._get_target_encoder()\n",
    "\n",
    "            target_projections, _ = target_encoder(images)\n",
    "            target_predications = self.target_projections.detach()\n",
    "\n",
    "            target_proj_one, target_proj_two = target_projections.chunk(2, dim=0)\n",
    "\n",
    "        loss_one = loss_fn(online_pred_one, target_proj_two)\n",
    "        loss_two = loss_fn(online_pred_two, target_proj_one)\n",
    "\n",
    "        loss = loss_one + loss_two\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve the function of 1/(x^3) = 3 => x = 1/(3^(1/3)) == 0.6933612743506345\n",
    "# solve the function of x^3 = 3 => x = 3^(1/3) == 1.4422495703074083"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ku-ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
